# ü§ñ Fintech Assistant - Demo Conversacional (FinBot)

Asistente virtual para una fintech utilizando modelos de lenguaje (LLM) con **LangChain**, **Ollama**, y una interfaz en **Streamlit**.

El asistente est√° dise√±ado para responder con claridad, precisi√≥n y empat√≠a sobre productos financieros: **tarjetas de d√©bito**, **tarjetas de cr√©dito** y **pr√©stamos**, aplicando t√©cnicas avanzadas como **prompt engineering** y **chain-of-thought reasoning**.

---

## Tecnolog√≠as utilizadas

- [LangChain](https://www.langchain.com/) - Orquestaci√≥n de LLMs
- [Ollama](https://ollama.com/) - Modelos locales (ej: Mistral, Llama)
- [Streamlit](https://streamlit.io/) - Interfaz de usuario r√°pida
- Python 3.11+

---

## Ejecuci√≥n local

### 1. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 2. Instalar y ejecutar el modelo con Ollama

Para correr modelos localmente (como Mistral), este proyecto utiliza **[Ollama](https://ollama.com/)**, una plataforma que permite descargar y ejecutar LLMs en tu m√°quina sin depender de la nube.

#### ‚û§ Instalaci√≥n de Ollama

Seg√∫n tu sistema operativo:

- **macOS**:
  ```bash
  brew install ollama
  ```
- **Windows**:
  - Descarg√° el instalador desde: https://ollama.com/download
  - Ejecutalo y segu√≠ las instrucciones.
- **Linux (Debian/Ubuntu)**:
  ```bash
  curl -fsSL https://ollama.com/install.sh | sh
  ```

Verific√° que est√© instalado correctamente:

```bash
ollama --version
```

#### ‚û§ Descargar y correr el modelo Mistral

Una vez instalado Ollama, ejecut√°:

```bash
ollama run mistral
```

Esto descargar√° autom√°ticamente el modelo **Mistral** si es la primera vez que lo us√°s.

---

### 3. Iniciar la aplicaci√≥n

```bash
streamlit run core/api/main.py
```

La app se abrir√° autom√°ticamente en tu navegador en `http://localhost:8501`.

---

## Funcionalidades principales

- Prompt din√°mico basado en rol, ejemplos y razonamiento
- Evaluaci√≥n con modo razonamiento interno (CoT)
- Clasificaci√≥n autom√°tica de consultas por producto
- Uso de conocimiento estructurado (JSON)
- Modular y preparado para escalar con RAG o agentes

---

## Modo evaluaci√≥n

Pod√©s ejecutar el asistente en modo evaluaci√≥n para obtener reasoning + respuesta final usando:

```python
eval_mode=True  # en el build_prompt()
```

---

## Evaluaci√≥n

El proyecto incluye:
- M√©tricas autom√°ticas v√≠a logging
- Checklist manual de calidad
- Tests adversariales para alineamiento √©tico

M√°s detalles en [`docs/evaluation_strategy.md`](docs/evaluation_strategy.md)